{
 "cells": [
  {
   "cell_type": "raw",
   "id": "1a9f016a",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"PIONEER Treatment Patterns Study\"\n",
    "output: html_document\n",
    "date: \"`r Sys.Date()`\"\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa5c237",
   "metadata": {
    "name": "setup",
    "tags": [
     "remove_cell"
    ]
   },
   "outputs": [],
   "source": [
    "knitr::opts_chunk$set(echo = TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6a501d",
   "metadata": {},
   "source": [
    "This Rmarkdown document contains the code to run the PIONEER Treatment Patterns Study. The code has been largely adapted from the [PIONEERmetastaticTreatment](https://github.com/bdemeulder/PIONEERmetastaticTreatment) study. It has been refactored into an RMarkdown document to facilitate readability.\n",
    "\n",
    "The study can be executed by rendering this documnent all at once or by running each code block one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16adec58",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15831296",
   "metadata": {
    "eval": false,
    "lines_to_next_cell": 2,
    "name": "install-dependencies"
   },
   "outputs": [],
   "source": [
    "# This only needs to be done once\n",
    "install.packages(\"devtools\")\n",
    "install.packages(\"survminer\")\n",
    "devtools::install_github(\"OHDSI/CohortDiagnostics\")\n",
    "devtools::install_github(\"OHDSI/CohortGenerator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c49ce7",
   "metadata": {},
   "source": [
    "Change the parameters in the code chunck below to match your database. This is the only code that needs to be edited to run the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee994bc",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "set-study-parameters"
   },
   "outputs": [],
   "source": [
    "library(DatabaseConnector)\n",
    "library(dplyr, warn.conflicts = FALSE)\n",
    "library(here)\n",
    "library(glue)\n",
    "# connectionDetails <- createConnectionDetails(\"postgresql\", user = \"postgres\", password = \"\", server = \"localhost/covid\")\n",
    "# con <- connect(cd)\n",
    "# dbGetQuery(con, \"select * from cdm5.person limit 8\")\n",
    "# disconnect(con)\n",
    "# \n",
    "# connectionDetails <- createConnectionDetails(dbms = \"postgresql\",\n",
    "#                                              server = \"testnode.arachnenetwork.com/synpuf_110k\",\n",
    "#                                              user = \"ohdsi\",\n",
    "#                                              password = Sys.getenv(\"ODYS_DB_PASSWORD\"),\n",
    "#                                              port = \"5441\")\n",
    "\n",
    "connectionDetails <- createConnectionDetails(dbms = \"postgresql\",\n",
    "                                             server = \"localhost/synpuf100k\",\n",
    "                                             user = \"postgres\",\n",
    "                                             password = \"\")\n",
    "\n",
    "connection = NULL\n",
    "# cdmDatabaseSchema = \"cdm5\"\n",
    "cdmDatabaseSchema = \"cdm531\"\n",
    "oracleTempSchema = NULL\n",
    "cohortDatabaseSchema = \"scratch\"\n",
    "# cohortDatabaseSchema = \"adam_black_results\"\n",
    "cohortStagingTable = \"cohort_stg\"\n",
    "cohortTable = \"cohort\"\n",
    "featureSummaryTable = \"cohort_smry\"\n",
    "cohortIdsToExcludeFromExecution = c()\n",
    "cohortIdsToExcludeFromResultsExport = NULL\n",
    "# cohortGroups = getUserSelectableCohortGroups()\n",
    "exportFolder = here::here(\"export\")\n",
    "databaseId = \"Synpuf\"\n",
    "databaseName = databaseId\n",
    "databaseDescription = \"Synthetic medicare claims 100k person sample\"\n",
    "useBulkCharacterization = FALSE\n",
    "minCellCount = 5\n",
    "minimumSubjectCountForCharacterization = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d4b45",
   "metadata": {
    "lines_to_next_cell": 2,
    "name": "source-R-files"
   },
   "outputs": [],
   "source": [
    "# Source R code files in this project\n",
    "purrr::walk(list.files(here(\"R\"), full.names = TRUE), source)\n",
    "\n",
    "if (!file.exists(exportFolder)) {\n",
    "  dir.create(exportFolder, recursive = TRUE)\n",
    "}\n",
    "\n",
    "ParallelLogger::addDefaultFileLogger(file.path(exportFolder, \"PioneerTreatmentPathways.txt\"))\n",
    "ParallelLogger::logInfo(.systemInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313e763e",
   "metadata": {},
   "source": [
    "## Check connection to database\n",
    "\n",
    "Confirm that the database connection works and that we have write access to the `cohortDatabaseSchema`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e05098",
   "metadata": {
    "name": "check-database-access"
   },
   "outputs": [],
   "source": [
    "conn <- connect(connectionDetails)\n",
    "\n",
    "# check query access\n",
    "df <- renderTranslateQuerySql(conn, \n",
    "                              \"select count(*) as n_persons from @cdmDatabaseSchema.person\",\n",
    "                              cdmDatabaseSchema = cdmDatabaseSchema) %>% \n",
    "  rename_all(tolower)\n",
    "\n",
    "message(glue::glue(\"Number of rows in the person table: {df$n_persons}\"))\n",
    "\n",
    "insertTable(conn, cohortDatabaseSchema, \"iris_temp\", iris)\n",
    "\n",
    "df <- renderTranslateQuerySql(conn, \n",
    "                              \"select count(*) as n from @cohortDatabaseSchema.iris_temp\",\n",
    "                              cohortDatabaseSchema = cohortDatabaseSchema) %>% \n",
    "  rename_all(tolower)\n",
    "\n",
    "renderTranslateExecuteSql(conn, \n",
    "                          \"drop table @cohortDatabaseSchema.iris_temp\",\n",
    "                          cohortDatabaseSchema = cohortDatabaseSchema,\n",
    "                          progressBar = FALSE)\n",
    "\n",
    "if (df$n != nrow(iris)) {\n",
    "  rlang::abort(\"Error with database write access check\")\n",
    "} else {\n",
    "  message(\"Write access confirmed\")\n",
    "}\n",
    "\n",
    "disconnect(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330d603e",
   "metadata": {},
   "source": [
    "# Save database metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb210ff",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ParallelLogger::logInfo(\"Saving database metadata\")\n",
    "\n",
    "con <- connect(connectionDetails)\n",
    "\n",
    "vocabInfo <- renderTranslateQuerySql(\n",
    "  con,\n",
    "  glue(\"SELECT vocabulary_version FROM {cdmDatabaseSchema}.vocabulary WHERE vocabulary_id = 'None';\"))\n",
    "\n",
    "database <- data.frame(databaseId = databaseId,\n",
    "                       databaseName = databaseName,\n",
    "                       description = databaseDescription,\n",
    "                       vocabularyVersion = vocabInfo[[1]],\n",
    "                       isMetaAnalysis = 0)\n",
    "\n",
    "readr::write_csv(database, file.path(exportFolder, \"database.csv\"))\n",
    "\n",
    "andrData <- Andromeda::andromeda()\n",
    "andrData$database <- database\n",
    "\n",
    "disconnect(con)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8f0769",
   "metadata": {},
   "source": [
    "# Generate Study Cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "start <- Sys.time()\n",
    "\n",
    "# Instantiate cohorts -----------------------------------------------------------------------\n",
    "cohortDefinitionSet <- readr::read_csv(file.path(\"inst\", \"settings\", \"CohortsToCreate.csv\"), \n",
    "                                       show_col_types = FALSE) %>% \n",
    "  mutate(cohortName = name,\n",
    "         sqlPath = file.path(\"inst\", \"sql\", paste0(name, \".sql\")),\n",
    "         sql = purrr::map_chr(sqlPath, readr::read_file))\n",
    "\n",
    "cohortTableNames <- CohortGenerator::getCohortTableNames(cohortStagingTable)\n",
    "\n",
    "if (!file.exists(here(exportFolder, \"incremental\", \"GeneratedCohorts.csv\"))) {\n",
    "  CohortGenerator::createCohortTables(\n",
    "    connectionDetails = connectionDetails,\n",
    "    cohortDatabaseSchema = cohortDatabaseSchema,\n",
    "    cohortTableNames = cohortTableNames,\n",
    "    incremental = TRUE\n",
    "  )\n",
    "}\n",
    "\n",
    "ParallelLogger::logInfo(\"**********************************************************\")\n",
    "ParallelLogger::logInfo(\"  ---- Creating cohorts ---- \")\n",
    "ParallelLogger::logInfo(\"**********************************************************\")\n",
    "\n",
    "CohortGenerator::generateCohortSet(\n",
    "  connectionDetails = connectionDetails,\n",
    "  cdmDatabaseSchema = cdmDatabaseSchema,\n",
    "  cohortDatabaseSchema = cohortDatabaseSchema,\n",
    "  cohortDefinitionSet = cohortDefinitionSet,\n",
    "  cohortTableNames = cohortTableNames,\n",
    "  incremental = TRUE,\n",
    "  incrementalFolder = file.path(exportFolder, \"incremental\")\n",
    ")\n",
    "\n",
    "cohortCounts <- CohortGenerator::getCohortCounts(\n",
    "    connectionDetails = connectionDetails,\n",
    "    cohortDatabaseSchema = cohortDatabaseSchema,\n",
    "    cohortTable = cohortStagingTable) %>%  \n",
    "  left_join(select(cohortDefinitionSet, cohortId, cohortName = atlasName, group), ., by = \"cohortId\") %>% \n",
    "  mutate(cohortEntries = coalesce(cohortEntries, 0),\n",
    "         cohortSubjects = coalesce(cohortSubjects, 0),\n",
    "         databaseId = databaseId)\n",
    "\n",
    "readr::write_csv(cohortCounts, file.path(\"export\", paste0(databaseId, \"CohortCounts.csv\")))\n",
    "\n",
    "if (all(filter(cohortCounts, group == \"Target\") %>% pull(cohortEntries) == 0)) {\n",
    "  stop(\"All target cohorts are empty. You cannot execute this study.\")\n",
    "}\n",
    "delta <- Sys.time() - start\n",
    "msg <- paste(\"Generating cohorts took\", signif(delta, 3), attr(delta, \"units\"))\n",
    "ParallelLogger::logInfo(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730a2e39",
   "metadata": {},
   "source": [
    "Censor cohorts that have counts lower than min cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e3e0aa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ParallelLogger::logInfo(\" ---- Copy cohorts to main table ---- \")\n",
    "\n",
    "con <- connect(connectionDetails)\n",
    "\n",
    "# Idendtify feasable analyses\n",
    "# Target count >= minCellCount\n",
    "# Target with strata (TwS) >= minCellCount AND Target with strata (TwoS) >= minCellCount\n",
    "\n",
    "# targetStrataXref is a table with all combinations of target cohorts with and without strata\n",
    "targetStrataXref <- readr::read_csv(file.path(\"inst\", \"settings\", \"targetStrataXref.csv\"), \n",
    "                                    show_col_types = FALSE)\n",
    "\n",
    "df <- targetStrataXref %>% \n",
    "  select(targetId, strataId, cohortId, cohortType) %>% \n",
    "  inner_join(select(cohortCounts, targetId = cohortId, targetCount = cohortEntries), by = \"targetId\")\n",
    "\n",
    "# TODO decide how to filter these\n",
    "\n",
    "\n",
    "CohortGenerator::createCohortTables(connection = con,\n",
    "                                    cohortDatabaseSchema = cohortDatabaseSchema,\n",
    "                                    cohortTableNames = CohortGenerator::getCohortTableNames(cohortTable))\n",
    "\n",
    "sql <- c(\"\n",
    "  INSERT INTO @cohort_database_schema.@cohort_table \n",
    "  SELECT \n",
    "    cohort_definition_id,\n",
    "    subject_id,\n",
    "    cohort_start_date,\n",
    "    cohort_end_date\n",
    "  FROM @cohort_database_schema.@cohort_staging_table\n",
    "  WHERE cohort_definition_id IN (@feasable_cohort_defition_ids);\n",
    "   \n",
    "  CREATE INDEX IDX_@cohort_table \n",
    "  ON @cohort_database_schema.@cohort_table (cohort_definition_id, subject_id, cohort_start_date);\") %>% \n",
    "  SqlRender::render(\n",
    "    cohort_database_schema = cohortDatabaseSchema,\n",
    "    cohort_staging_table = cohortStagingTable,\n",
    "    cohort_table = cohortTable,\n",
    "    feasable_cohort_defition_ids = df$targetId) %>% \n",
    "  assertNoParameters() %>% \n",
    "  SqlRender::translate(targetDialect = attr(connection, \"dbms\"))\n",
    "  \n",
    "ParallelLogger::logInfo(\"Copy and censor cohorts to main analysis table\")\n",
    "executeSql(con, sql)\n",
    "disconnect(con)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c76185",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "con <- DatabaseConnector::connect(connectionDetails)\n",
    "\n",
    "n1 <- renderTranslateQuerySql(con, glue::glue(\"select count(*) as n from {cohortDatabaseSchema}.{cohortStagingTable}\")) %>%\n",
    "  rename_all(tolower) %>% \n",
    "  pull(n)\n",
    "\n",
    "n2 <- renderTranslateQuerySql(con, glue::glue(\"select count(*) as n from {cohortDatabaseSchema}.{cohortTable}\")) %>%\n",
    "  rename_all(tolower) %>% \n",
    "  pull(n)\n",
    "\n",
    "DatabaseConnector::disconnect(con)\n",
    "message(glue(\"cohort staging table created with {n1} rows.\"))\n",
    "message(glue(\"cohort table created with {n2} rows.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350acc74",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "CohortGenerator::getCohortCounts(\n",
    "    connectionDetails = connectionDetails,\n",
    "    cohortDatabaseSchema = cohortDatabaseSchema,\n",
    "    cohortTable = cohortTable) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f38a808",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f529a6aa",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Compute the features\n",
    "ParallelLogger::logInfo(\"**********************************************************\")\n",
    "ParallelLogger::logInfo(\" ---- Create feature proportions ---- \")\n",
    "ParallelLogger::logInfo(\"**********************************************************\")\n",
    "createFeatureProportions(connectionDetails = connectionDetails,\n",
    "                         cohortDatabaseSchema = cohortDatabaseSchema,\n",
    "                         cohortStagingTable = cohortStagingTable,\n",
    "                         cohortTable = cohortTable,\n",
    "                         featureSummaryTable = featureSummaryTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e786c1d",
   "metadata": {},
   "source": [
    "# Count staging cohorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64f157d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ParallelLogger::logInfo(\"Counting staging cohorts\")\n",
    "\n",
    "counts <- CohortGenerator::getCohortCounts(connectionDetails = connectionDetails,\n",
    "                                           cohortDatabaseSchema = cohortDatabaseSchema,\n",
    "                                           cohortTable = cohortStagingTable)\n",
    "\n",
    "if (nrow(counts) > 0) {\n",
    "  counts$databaseId <- databaseId\n",
    "  counts <- enforceMinCellValue(counts, \"cohortEntries\", minCellCount)\n",
    "  counts <- enforceMinCellValue(counts, \"cohortSubjects\", minCellCount)\n",
    "}\n",
    "\n",
    "allStudyCohorts <- bind_rows(\n",
    "  readr::read_csv(here(\"inst\", \"settings\", \"CohortsToCreate.csv\"), \n",
    "                  col_select = c(\"name\" = \"atlasName\", \"cohortId\"),\n",
    "                  show_col_types = FALSE),\n",
    "  \n",
    "  readr::read_csv(here(\"inst\", \"settings\", \"targetStrataXref.csv\"), \n",
    "                  col_select = c(\"name\", \"cohortId\"),\n",
    "                  col_types = \"cd\",\n",
    "                  show_col_types = FALSE)\n",
    "  )\n",
    "\n",
    "allCounts <- dplyr::left_join(allStudyCohorts, counts, by = \"cohortId\") %>% \n",
    "  mutate(across(c(cohortEntries, cohortSubjects), ~tidyr::replace_na(., 0))) %>% \n",
    "  mutate(databaseId = databaseId)\n",
    "\n",
    "andrData$cohort_staging_count = allCounts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71860225",
   "metadata": {},
   "source": [
    "# Generate survival info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10be512",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "ParallelLogger::logInfo(\"Generating time to event data\")\n",
    "start <- Sys.time()\n",
    "\n",
    "targetStrataXref <- readr::read_csv(here(\"inst\", \"settings\", \"targetStrataXref.csv\"), show_col_types = FALSE)\n",
    "cohortsToCreate <- readr::read_csv(here(\"inst\", \"settings\", \"cohortsToCreate.csv\"), show_col_types = FALSE)\n",
    "\n",
    "targetCohortIds <- cohortsToCreate %>% \n",
    "  filter(group == \"Target\") %>% \n",
    "  pull(cohortId)\n",
    "\n",
    "targetIds <- c(targetCohortIds, targetStrataXref$cohortId)\n",
    "\n",
    "events <- readr::read_csv(here(\"inst\", \"settings\", \"TimeToEvent.csv\"), show_col_types = F) %>% \n",
    "  mutate(outcomeCohortIds = stringr::str_replace_all(outcomeCohortIds, \";\", \",\"))\n",
    "\n",
    "connection <- connect(connectionDetails)\n",
    "\n",
    "eventIds <- events %>% dplyr::pull(eventId)\n",
    "  \n",
    "# .eventId = 1\n",
    "timeToEvent <- purrr::map_dfr(eventIds, function(.eventId) {\n",
    "  outcomeIds <- events %>% \n",
    "    dplyr::filter(eventId == .eventId) %>% \n",
    "    dplyr::pull(outcomeCohortIds)\n",
    "    \n",
    "  sql <- SqlRender::render(\"\n",
    "    SELECT cohort_definition_id AS target_id, \n",
    "       row_number() OVER (PARTITION BY cohort_definition_id) AS id,\n",
    "       DATEDIFF(day, cohort_start_date, event_date) AS time_to_event,\n",
    "       event\n",
    "    FROM (\n",
    "         SELECT t.cohort_definition_id, t.cohort_start_date,\n",
    "                coalesce(min(o.cohort_start_date), max(t.cohort_end_date)) AS event_date,\n",
    "                CASE WHEN min(o.cohort_start_date) IS NULL THEN 0 ELSE 1 END AS event\n",
    "         FROM @cohort_database_schema.@cohort_table t\n",
    "             LEFT JOIN (\n",
    "                SELECT subject_id, MIN (cohort_start_date) AS cohort_start_date\n",
    "                FROM @cohort_database_schema.@cohort_table\n",
    "                WHERE cohort_definition_id IN (@outcome_ids)\n",
    "                GROUP BY subject_id\n",
    "              ) o\n",
    "             ON t.subject_id = o.subject_id\n",
    "                AND o.cohort_start_date >= t.cohort_start_date\n",
    "                AND o.cohort_start_date <= t.cohort_end_date\n",
    "         WHERE t.cohort_definition_id IN (@target_ids)\n",
    "         GROUP BY t.cohort_definition_id, t.subject_id, t.cohort_start_date\n",
    "         ) tab;\n",
    "    \",\n",
    "    cohort_database_schema = cohortDatabaseSchema,\n",
    "    cohort_table = cohortTable,\n",
    "    outcome_ids = outcomeIds, \n",
    "    target_ids = paste(targetIds, collapse = ', ')) %>% \n",
    "  assertNoParameters() %>% \n",
    "  SqlRender::translate(dbms(connection))\n",
    "    \n",
    "  km_grouped <- DatabaseConnector::querySql(connection, sql, snakeCaseToCamelCase = T)\n",
    "  \n",
    "  # .targetId = 1\n",
    "  purrr::map_dfr(targetIds, function(.targetId){\n",
    "    \n",
    "    km <- km_grouped %>% dplyr::filter(targetId == .targetId)\n",
    "    \n",
    "    if (nrow(km) < 30 | length(km$event[km$event == 1]) < 1) {return(NULL)}\n",
    "\n",
    "    # TODO: Change to Cyclops\n",
    "    surv_info <- survival::survfit(survival::Surv(timeToEvent, event) ~ 1, data = km)\n",
    "    surv_info <- survminer::surv_summary(surv_info)\n",
    "    data.frame(targetId = .targetId, eventId = .eventId, time = surv_info$time, surv = surv_info$surv, \n",
    "               n.censor = surv_info$n.censor, n.event = surv_info$n.event, n.risk = surv_info$n.risk,\n",
    "               lower = surv_info$lower, upper = surv_info$upper, databaseId = databaseId)\n",
    "  })\n",
    "  \n",
    "})\n",
    "\n",
    "andrData$cohort_time_to_event <- timeToEvent\n",
    "\n",
    "disconnect(connection)\n",
    "\n",
    "delta <- Sys.time() - start\n",
    "msg <- paste(\"Generating time to event data took\", signif(delta, 3), attr(delta, \"units\"))\n",
    "print(msg)\n",
    "ParallelLogger::logInfo(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825ee34a",
   "metadata": {},
   "source": [
    "# Generate time to treatment switch info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3f7442",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ParallelLogger::logInfo(\"Generating time to treatment switch data\")\n",
    "ParallelLogger::logInfo(\"Create treatment tables\")\n",
    "\n",
    "start <- Sys.time()\n",
    "connection <- connect(connectionDetails)\n",
    "\n",
    "sql <- c(\"\n",
    "  DROP TABLE IF EXISTS @cohort_database_schema.drug_codesets;\n",
    "  CREATE TABLE @cohort_database_schema.drug_codesets\n",
    "  (\n",
    "      codeset_tag VARCHAR NOT NULL,\n",
    "      concept_id BIGINT NOT NULL\n",
    "  );\n",
    "  \n",
    "  \n",
    "  INSERT INTO @cohort_database_schema.drug_codesets (codeset_tag, concept_id)\n",
    "  SELECT codeset_tag, concept_id\n",
    "  FROM (\n",
    "       --ADT\n",
    "       SELECT 'ADT' AS codeset_tag, c.concept_id\n",
    "       FROM (\n",
    "            SELECT DISTINCT I.concept_id\n",
    "            FROM (\n",
    "                 SELECT concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT\n",
    "                 WHERE concept_id IN (19058410, 739471, 35834903, 1343039, 19089810, 1366310, 1351541, 1344381, 19010792,\n",
    "                                      1356461, 1500211, 1300978, 1315286, 35807385, 35807349)\n",
    "                 UNION\n",
    "                 SELECT C.concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT C\n",
    "                     JOIN @cdm_database_schema.CONCEPT_ANCESTOR ca\n",
    "                 ON C.concept_id = ca.descendant_concept_id\n",
    "                     AND ca.ancestor_concept_id IN (19058410, 739471, 35834903, 1343039, 19089810, 1366310, 1351541, 1344381,\n",
    "                                                    19010792, 1356461, 1500211, 1300978, 1315286, 35807385, 35807349)\n",
    "                     AND C.invalid_reason IS NULL\n",
    "                 ) I\n",
    "            ) C\n",
    "  \n",
    "       UNION\n",
    "       \n",
    "       -- ARTA\n",
    "       SELECT 'ARTA' AS codeset_tag, c.concept_id\n",
    "       FROM (\n",
    "            SELECT DISTINCT I.concept_id\n",
    "            FROM (\n",
    "                 SELECT concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT\n",
    "                 WHERE concept_id IN (40239056, 963987, 42900250, 1361291)\n",
    "                 UNION\n",
    "                 SELECT C.concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT C\n",
    "                     JOIN @cdm_database_schema.CONCEPT_ANCESTOR ca\n",
    "                 ON C.concept_id = ca.descendant_concept_id\n",
    "                     AND ca.ancestor_concept_id IN (40239056, 963987, 42900250, 1361291)\n",
    "                     AND C.invalid_reason IS NULL\n",
    "                 ) I\n",
    "            ) C\n",
    "  \n",
    "       UNION\n",
    "       \n",
    "       --Chemo\n",
    "       SELECT 'Chemo' AS codeset_tag, c.concept_id\n",
    "       FROM (\n",
    "            SELECT DISTINCT I.concept_id\n",
    "            FROM (\n",
    "                 SELECT concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT\n",
    "                 WHERE concept_id IN (1315942, 40222431, 1378382)\n",
    "                 UNION\n",
    "                 SELECT C.concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT C\n",
    "                     JOIN @cdm_database_schema.CONCEPT_ANCESTOR ca\n",
    "                 ON C.concept_id = ca.descendant_concept_id\n",
    "                     AND ca.ancestor_concept_id IN (1315942, 40222431, 1378382)\n",
    "                     AND C.invalid_reason IS NULL\n",
    "                 ) I\n",
    "            ) C\n",
    "  \n",
    "       UNION\n",
    "       \n",
    "       --PARP\n",
    "       SELECT 'PARP' AS codeset_tag, c.concept_id\n",
    "       FROM (\n",
    "            SELECT DISTINCT I.concept_id\n",
    "            FROM (\n",
    "                 SELECT concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT\n",
    "                 WHERE concept_id IN (45892579, 1718850)\n",
    "                 UNION\n",
    "                 SELECT C.concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT C\n",
    "                     JOIN @cdm_database_schema.CONCEPT_ANCESTOR ca\n",
    "                 ON C.concept_id = ca.descendant_concept_id\n",
    "                     AND ca.ancestor_concept_id IN (45892579, 1718850)\n",
    "                     AND C.invalid_reason IS NULL\n",
    "                 ) I\n",
    "            ) C\n",
    "  \n",
    "       UNION\n",
    "       \n",
    "       --Immunotherapy\n",
    "       SELECT 'Immuno' AS codeset_tag, c.concept_id\n",
    "       FROM (\n",
    "            SELECT DISTINCT I.concept_id\n",
    "            FROM (\n",
    "                 SELECT concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT\n",
    "                 WHERE concept_id IN (45775965, 40224095)\n",
    "                 UNION\n",
    "                 SELECT C.concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT C\n",
    "                     JOIN @cdm_database_schema.CONCEPT_ANCESTOR ca\n",
    "                 ON C.concept_id = ca.descendant_concept_id\n",
    "                     AND ca.ancestor_concept_id IN (45775965, 40224095)\n",
    "                     AND C.invalid_reason IS NULL\n",
    "                 ) I\n",
    "            ) C\n",
    "  \n",
    "       UNION\n",
    "       \n",
    "       --lutetium\n",
    "       SELECT 'lutetium' AS codeset_tag, c.concept_id\n",
    "       FROM (\n",
    "            SELECT DISTINCT I.concept_id\n",
    "            FROM (\n",
    "                 SELECT concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT\n",
    "                 WHERE concept_id IN (44816340)\n",
    "                 UNION\n",
    "                 SELECT C.concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT C\n",
    "                     JOIN @cdm_database_schema.CONCEPT_ANCESTOR ca\n",
    "                 ON C.concept_id = ca.descendant_concept_id\n",
    "                     AND ca.ancestor_concept_id IN (44816340)\n",
    "                     AND C.invalid_reason IS NULL\n",
    "                 ) I\n",
    "            ) C\n",
    "  \n",
    "       UNION\n",
    "       \n",
    "       --radium223\n",
    "       SELECT 'radium' AS codeset_tag, c.concept_id\n",
    "       FROM (\n",
    "            SELECT DISTINCT I.concept_id\n",
    "            FROM (\n",
    "                 SELECT concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT\n",
    "                 WHERE concept_id IN (45775578, 902727, 43526934)\n",
    "                 UNION\n",
    "                 SELECT C.concept_id\n",
    "                 FROM @cdm_database_schema.CONCEPT C\n",
    "                     JOIN @cdm_database_schema.CONCEPT_ANCESTOR ca\n",
    "                 ON C.concept_id = ca.descendant_concept_id\n",
    "                     AND ca.ancestor_concept_id IN (45775578, 902727, 43526934)\n",
    "                     AND C.invalid_reason IS NULL\n",
    "                 ) I\n",
    "            LEFT JOIN\n",
    "                (\n",
    "                SELECT concept_id\n",
    "                FROM @cdm_database_schema.CONCEPT\n",
    "                WHERE concept_id IN (41267222)\n",
    "  \n",
    "                ) E\n",
    "                ON I.concept_id = E.concept_id\n",
    "            WHERE E.concept_id IS NULL\n",
    "            ) C\n",
    "       ) tab\n",
    "  ;\n",
    "  \n",
    "  \n",
    "  -- assign drug tag to each drug_exposure instead of individual drug concept_ids \n",
    "  -- TODO add analysis for number of patients less that 183 days in cohort\n",
    "  DROP TABLE IF EXISTS @cohort_database_schema.treatment_tagged;\n",
    "  \n",
    "  CREATE TABLE @cohort_database_schema.treatment_tagged(\n",
    "    cohort_definition_id int, \n",
    "    person_id bigint,\n",
    "    codeset_tag varchar,\n",
    "    drug_exposure_start_date date,\n",
    "    cohort_start_date date,\n",
    "    cohort_end_date date\n",
    "  );\n",
    "  \n",
    "  WITH tab AS(\n",
    "    SELECT coh.cohort_definition_id, de.person_id,\n",
    "           cs.codeset_tag, de.drug_exposure_start_date,\n",
    "           coh.cohort_start_date,\n",
    "           coh.cohort_end_date\n",
    "    FROM @cdm_database_schema.drug_exposure de\n",
    "    JOIN @cohort_database_schema.@cohort_table coh\n",
    "        ON de.person_id = coh.subject_id\n",
    "    JOIN @cohort_database_schema.drug_codesets cs\n",
    "        ON cs.concept_id = de.drug_concept_id\n",
    "        )\n",
    "  INSERT INTO @cohort_database_schema.treatment_tagged\n",
    "  SELECT * \n",
    "  FROM tab \n",
    "  WHERE cohort_definition_id IN (@treatment_cohort_ids)\n",
    "    AND cohort_end_date >= drug_exposure_start_date\n",
    "    AND cohort_start_date <= drug_exposure_start_date\n",
    "    AND DATEDIFF(day, cohort_start_date, cohort_end_date) > 183\n",
    "  ORDER BY cohort_definition_id, person_id, drug_exposure_start_date;\n",
    "  \n",
    "  \n",
    "  -- collect initial treatment patterns info\n",
    "  DROP TABLE IF EXISTS @cohort_database_schema.treatment_pat;\n",
    "  CREATE TABLE @cohort_database_schema.treatment_pat AS\n",
    "  SELECT DENSE_RANK() OVER(PARTITION BY cohort_definition_id ORDER BY person_id) AS id,\n",
    "         cohort_definition_id, person_id, before_codeset_tag, first_exposure, \n",
    "         after_codeset_tag, after_first_exposure, cohort_start_date, cohort_end_date\n",
    "  FROM (\n",
    "        SELECT COALESCE(before_cohort_id, after_cohort_id) AS cohort_definition_id, \n",
    "               COALESCE(before_person_id, after_person_id) AS person_id, before_codeset_tag, first_exposure,\n",
    "               after_codeset_tag, COALESCE(after_first_exposure, first_exposure) AS after_first_exposure, \n",
    "               COALESCE(before.cohort_start_date, after.cohort_start_date) AS cohort_start_date,\n",
    "               COALESCE(before.cohort_end_date, after.cohort_end_date) AS cohort_end_date\n",
    "        FROM (\n",
    "              -- first six months treatment\n",
    "              SELECT cohort_definition_id AS before_cohort_id, \n",
    "                     person_id AS before_person_id, \n",
    "                     codeset_tag AS before_codeset_tag,\n",
    "                     MIN(drug_exposure_start_date) AS first_exposure, \n",
    "                     cohort_start_date, \n",
    "                     cohort_end_date\n",
    "              FROM @cohort_database_schema.treatment_tagged tp\n",
    "              WHERE drug_exposure_start_date <= DATEADD(day, 183, cohort_start_date)\n",
    "              GROUP BY cohort_definition_id, person_id, codeset_tag, cohort_start_date, cohort_end_date\n",
    "              ) before\n",
    "        FULL JOIN (\n",
    "              -- post six months treatment\n",
    "              SELECT cohort_definition_id AS after_cohort_id, person_id AS after_person_id, codeset_tag AS after_codeset_tag,\n",
    "                     MIN(drug_exposure_start_date) AS after_first_exposure, cohort_start_date, cohort_end_date\n",
    "              FROM @cohort_database_schema.treatment_tagged tp\n",
    "              WHERE drug_exposure_start_date > DATEADD(day, 183, cohort_start_date)\n",
    "              GROUP BY cohort_definition_id, person_id, codeset_tag, cohort_start_date, cohort_end_date\n",
    "              ) after\n",
    "        ON before.before_person_id = after.after_person_id\n",
    "          AND before.before_codeset_tag = after.after_codeset_tag\n",
    "          AND before_cohort_id = after_cohort_id\n",
    "        ORDER BY after.after_person_id, after_first_exposure\n",
    "        ) tab\n",
    "  ORDER BY cohort_definition_id;\n",
    "  \") %>% \n",
    "  SqlRender::render(\n",
    "    warnOnMissingParameters = TRUE,\n",
    "    cohort_database_schema = cohortDatabaseSchema,\n",
    "    cdm_database_schema = cdmDatabaseSchema,\n",
    "    treatment_cohort_ids = paste(targetIds, collapse = ', '),\n",
    "    cohort_table = cohortStagingTable) %>% \n",
    "  assertNoParameters() %>% \n",
    "  SqlRender::translate(dbms(connection))\n",
    "\n",
    "DatabaseConnector::executeSql(connection, sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ad6ce4",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ParallelLogger::logInfo(\"Get time to treatment switch\")\n",
    "\n",
    "deathCohortId <- events %>% dplyr::filter(name == 'Time to Death') %>% dplyr::pull(outcomeCohortIds)\n",
    "\n",
    "sql <- c(\"\n",
    "  SELECT cohort_definition_id, \n",
    "         ROW_NUMBER() OVER (PARTITION BY cohort_definition_id) AS id,\n",
    "         DATEDIFF(day, cohort_start_date, event_date) AS time_to_event,\n",
    "         event\n",
    "  FROM (\n",
    "        SELECT DISTINCT \n",
    "               tp.cohort_definition_id, tp.cohort_start_date, \n",
    "               COALESCE(trt.after_first_exposure, coh.cohort_start_date, tp.cohort_end_date) AS event_date,\n",
    "               CASE WHEN trt.after_first_exposure IS NULL AND \n",
    "                         coh.cohort_start_date IS NULL \n",
    "                    THEN 0 ELSE 1 END AS event\n",
    "        FROM @cohort_database_schema.treatment_pat tp\n",
    "        LEFT JOIN (\n",
    "            SELECT cohort_definition_id, person_id, \n",
    "                   MIN(after_first_exposure) AS after_first_exposure\n",
    "            FROM @cohort_database_schema.treatment_pat\n",
    "            WHERE first_exposure is NULL\n",
    "            GROUP BY cohort_definition_id, person_id\n",
    "            ) trt\n",
    "        ON tp.cohort_definition_id = trt.cohort_definition_id\n",
    "          AND tp.person_id = trt.person_id\n",
    "        LEFT JOIN (\n",
    "            SELECT subject_id, cohort_start_date \n",
    "            FROM @cohort_database_schema.@cohort_table \n",
    "            WHERE cohort_definition_id = @death_cohort_id\n",
    "            ) coh\n",
    "        ON tp.person_id = coh.subject_id\n",
    "       ) tab\n",
    "  ORDER BY cohort_definition_id, id;\") %>% \n",
    "  SqlRender::render(\n",
    "    cohort_database_schema = cohortDatabaseSchema,\n",
    "    cohort_table = cohortStagingTable,\n",
    "    death_cohort_id = deathCohortId\n",
    "  ) %>% \n",
    "  assertNoParameters() %>% \n",
    "  SqlRender::translate(dbms(connection))\n",
    "\n",
    "data <- DatabaseConnector::querySql(connection, sql, snakeCaseToCamelCase = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ed5516",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "#calculate locality metrics for Time to Treatment Switch\n",
    "\n",
    "metrics <- data %>%\n",
    "  dplyr::filter(event == 1) %>% \n",
    "  dplyr::select(cohortDefinitionId, timeToEvent) %>% \n",
    "  dplyr::group_by(cohortDefinitionId) %>% \n",
    "  dplyr::summarise(minimum = min(timeToEvent),\n",
    "                     q1 = quantile(timeToEvent, 0.25),\n",
    "                     median = median(timeToEvent),\n",
    "                     q3 = quantile(timeToEvent, 0.75),\n",
    "                     maximum = max(timeToEvent)) %>% \n",
    "  dplyr::mutate(iqr = q3 - q1, analysisName = \"Time to Treatment Switch\") %>% \n",
    "  dplyr::relocate(iqr, .before = minimum)\n",
    "  \n",
    "timeToTreatmentSwitch <- purrr::map_df(targetIds, function(targetId){\n",
    "  data <- data %>% dplyr::filter(cohortDefinitionId == targetId) %>% dplyr::select(id, timeToEvent, event)\n",
    "  if (nrow(data) < 30 | length(data$event[data$event == 1]) < 1) {return(NULL)}\n",
    "  surv_info <- survival::survfit(survival::Surv(timeToEvent, event) ~ 1, data = data)\n",
    "  surv_info <- survminer::surv_summary(surv_info)\n",
    "  \n",
    "  data.frame(targetId = targetId, time = surv_info$time, surv = surv_info$surv, \n",
    "             n.censor = surv_info$n.censor, n.event = surv_info$n.event, n.risk = surv_info$n.risk,\n",
    "             lower = surv_info$lower, upper = surv_info$upper, databaseId = databaseId)\n",
    "})\n",
    "andrData$cohort_time_to_treatment_switch <- timeToTreatmentSwitch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21835c95",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ff33fb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ParallelLogger::logInfo(\"Get sankey data\")\n",
    "\n",
    "sql <- c(\"\n",
    "  SELECT pat.cohort_definition_id AS cohort_id, pat.id, \n",
    "         pat.before_codeset_tag, pat.after_codeset_tag\n",
    "  FROM  @cohort_database_schema.treatment_pat pat\n",
    "  LEFT JOIN (\n",
    "      SELECT cohort_definition_id, person_id, codeset_tag, \n",
    "             MAX(drug_exposure_start_date) AS last_exposure\n",
    "      FROM @cohort_database_schema.treatment_tagged\n",
    "      GROUP BY cohort_definition_id, person_id, codeset_tag\n",
    "      ) le\n",
    "  ON pat.cohort_definition_id = le.cohort_definition_id\n",
    "    AND pat.person_id = le.person_id\n",
    "    AND pat.before_codeset_tag = le.codeset_tag\n",
    "  LEFT JOIN (\n",
    "      -- take the earliest date of new drug exposure\n",
    "      SELECT  cohort_definition_id, person_id, MIN(after_first_exposure) first_switch\n",
    "      FROM @cohort_database_schema.treatment_pat\n",
    "      WHERE before_codeset_tag IS NULL\n",
    "      GROUP BY cohort_definition_id, person_id\n",
    "      ) fs\n",
    "  ON pat.cohort_definition_id = fs.cohort_definition_id\n",
    "    AND pat.person_id = fs.person_id\n",
    "  WHERE DATEDIFF(day, pat.cohort_start_date, pat.cohort_end_date) >= 183\n",
    "    AND first_exposure IS NOT NULL OR \n",
    "        DATEADD(day, @second_line_treatment_gap, first_switch) >= after_first_exposure\n",
    "  ORDER BY pat.cohort_definition_id, pat.person_id;\") %>% \n",
    "  SqlRender::render(\n",
    "    cohort_database_schema = cohortDatabaseSchema,\n",
    "    second_line_treatment_gap = '0'\n",
    "  ) %>% \n",
    "  assertNoParameters() %>% \n",
    "  SqlRender::translate(dbms(connection))\n",
    "\n",
    "data <- DatabaseConnector::querySql(connection, sql, snakeCaseToCamelCase = T)\n",
    "\n",
    "data <- data %>% \n",
    "  group_by(cohortId, id) %>% \n",
    "  mutate(first_line = paste(beforeCodesetTag, collapse = \" \"),\n",
    "         second_line = paste(afterCodesetTag, collapse = \" \")) %>%\n",
    "  select(id, cohortId, first_line, second_line) %>%\n",
    "  distinct() %>%\n",
    "  mutate(first_line = formatPattern(first_line),\n",
    "         second_line = formatPattern(second_line))\n",
    "\n",
    "treatmentPatternMap <- data.frame(name = unique(data$first_line))\n",
    "treatmentPatternMap$code <- 1:nrow(treatmentPatternMap)\n",
    "\n",
    "sankeyData <- dplyr::inner_join(data, treatmentPatternMap, by = c('first_line' = 'name')) %>% \n",
    "  dplyr::rename('sourceId' = 'code') %>%\n",
    "  dplyr::rename('sourceName' = 'first_line')\n",
    "\n",
    "rowCount <- nrow(treatmentPatternMap)\n",
    "treatmentPatternMap <- data.frame(name = unique(data$second_line))\n",
    "treatmentPatternMap$code <- (rowCount + 1):(nrow(treatmentPatternMap) + rowCount)\n",
    "\n",
    "sankeyData <- dplyr::inner_join(sankeyData, treatmentPatternMap, by = c('second_line' = 'name')) %>%\n",
    "  rename('targetId' = 'code') %>%\n",
    "  rename('targetName' = 'second_line')\n",
    "\n",
    "sankeyData <- sankeyData %>%\n",
    "  group_by(cohortId, sourceName, targetName, sourceId, targetId) %>%\n",
    "  summarise(value = dplyr::n(), .groups = \"drop\") %>%\n",
    "  filter(sourceName != 'discontinued') %>% \n",
    "  select_all()\n",
    "\n",
    "sankeyData$databaseId = databaseId\n",
    "andrData$treatment_sankey <- sankeyData\n",
    "\n",
    "delta <- Sys.time() - start\n",
    "ParallelLogger::logInfo(paste(\"Generating time to treatment switch data took\",\n",
    "                              signif(delta, 3),\n",
    "                              attr(delta, \"units\")))\n",
    "\n",
    "disconnect(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec943f3",
   "metadata": {},
   "source": [
    "# Locality estimation of some time periods "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f82be1b",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# median follow-up time\n",
    "ParallelLogger::logInfo(\"Time periods locality estimation\")\n",
    "\n",
    "connection <- connect(connectionDetails)\n",
    "\n",
    "start <- Sys.time()\n",
    "sql <- c(\"\n",
    "  WITH init_data AS (\n",
    "    SELECT cohort_definition_id, DATEDIFF(day, cohort_start_date, cohort_end_date) AS value\n",
    "    FROM @cohort_database_schema.@cohort_table\n",
    "    WHERE cohort_definition_id IN (@target_ids)\n",
    "  ),\n",
    "  details AS (\n",
    "    SELECT \n",
    "      cohort_definition_id,\n",
    "      value,\n",
    "      ROW_NUMBER() OVER (PARTITION BY cohort_definition_id ORDER BY value) AS row_number,\n",
    "      SUM(1) OVER (PARTITION BY cohort_definition_id) AS total\n",
    "    FROM init_data\n",
    "  ),\n",
    "  quartiles AS (\n",
    "    SELECT cohort_definition_id,\n",
    "      value,\n",
    "      AVG(CASE\n",
    "              WHEN row_number >= (FLOOR(total / 2.0) / 2.0)\n",
    "                  AND row_number <= (FLOOR(total / 2.0) / 2.0) + 1\n",
    "                  THEN value / 1.0\n",
    "          END\n",
    "          ) OVER (PARTITION BY cohort_definition_id) AS q1,\n",
    "      AVG(CASE\n",
    "              WHEN row_number >= (total / 2.0)\n",
    "                  AND row_number <= (total / 2.0) + 1\n",
    "                  THEN value / 1.0\n",
    "          END\n",
    "          ) OVER (PARTITION BY cohort_definition_id) AS median,\n",
    "      AVG(CASE\n",
    "              WHEN row_number >= (CEILING(total / 2.0) + (FLOOR(total / 2.0) / 2.0))\n",
    "                  AND row_number <= (CEILING(total / 2.0) + (FLOOR(total / 2.0) / 2.0) + 1)\n",
    "                  THEN value / 1.0\n",
    "          END\n",
    "          ) OVER (PARTITION BY cohort_definition_id) AS q3\n",
    "    FROM details\n",
    "  )\n",
    "  SELECT cohort_definition_id,\n",
    "         AVG(q3) - AVG(q1) AS IQR,\n",
    "         MIN(value) AS minimum,\n",
    "         AVG(q1) AS q1,\n",
    "         AVG(median) AS median,\n",
    "         AVG(q3) AS q3,\n",
    "         MAX(value) AS maximum,\n",
    "         'Follow up Time' AS analysis_name\n",
    "  FROM quartiles\n",
    "  GROUP BY cohort_definition_id;\") %>%\n",
    "  SqlRender::render(\n",
    "    cohort_database_schema = cohortDatabaseSchema,\n",
    "    cohort_table = cohortTable,\n",
    "    target_ids = paste(targetIds, collapse = \",\")) %>% \n",
    "  assertNoParameters() %>% \n",
    "  SqlRender::translate(dbms(connection))\n",
    "\n",
    "df <- DatabaseConnector::querySql(connection, sql, snakeCaseToCamelCase = T)\n",
    "\n",
    "metrics <- rbind(metrics, df)\n",
    "disconnect(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7149fd2a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "connection <- connect(connectionDetails)\n",
    "\n",
    "sql <- c(\"\n",
    "  WITH tab as (\n",
    "    SELECT cohort_definition_id, cohort_start_date, min(drug_exposure_start_date) as drug_exposure_date\n",
    "    FROM @cohort_database_schema.@cohort_table coh\n",
    "    JOIN @cdm_database_schema.drug_exposure de\n",
    "        ON coh.subject_id = de.person_id\n",
    "            AND de.drug_concept_id IN (\n",
    "                                      SELECT concept_id\n",
    "                                      FROM @cohort_database_schema.drug_codesets\n",
    "                                      )\n",
    "            AND de.drug_exposure_start_date >= coh.cohort_start_date\n",
    "            AND de.drug_exposure_start_date <= coh.cohort_end_date\n",
    "    WHERE coh.cohort_definition_id IN (@target_ids)\n",
    "    GROUP BY cohort_definition_id, subject_id, cohort_start_date\n",
    "    ORDER BY cohort_definition_id\n",
    "  ),\n",
    "  init_data AS(\n",
    "    SELECT cohort_definition_id,\n",
    "           DATEDIFF(day, cohort_start_date, drug_exposure_date) AS value\n",
    "    FROM tab\n",
    "  ),\n",
    "  details AS (\n",
    "    SELECT \n",
    "      cohort_definition_id,\n",
    "      value,\n",
    "      ROW_NUMBER() OVER (PARTITION BY cohort_definition_id ORDER BY value) AS row_number,\n",
    "      SUM(1) OVER (PARTITION BY cohort_definition_id) AS total\n",
    "    FROM init_data\n",
    "  ),\n",
    "  quartiles AS (\n",
    "    SELECT cohort_definition_id,\n",
    "      value,\n",
    "      AVG(CASE\n",
    "              WHEN row_number >= (FLOOR(total / 2.0) / 2.0)\n",
    "                  AND row_number <= (FLOOR(total / 2.0) / 2.0) + 1\n",
    "                  THEN value / 1.0\n",
    "          END\n",
    "          ) OVER (PARTITION BY cohort_definition_id) AS q1,\n",
    "      AVG(CASE\n",
    "              WHEN row_number >= (total / 2.0)\n",
    "                  AND row_number <= (total / 2.0) + 1\n",
    "                  THEN value / 1.0\n",
    "          END\n",
    "          ) OVER (PARTITION BY cohort_definition_id) AS median,\n",
    "      AVG(CASE\n",
    "              WHEN row_number >= (CEILING(total / 2.0) + (FLOOR(total / 2.0) / 2.0))\n",
    "                  AND row_number <= (CEILING(total / 2.0) + (FLOOR(total / 2.0) / 2.0) + 1)\n",
    "                  THEN value / 1.0\n",
    "          END\n",
    "          ) OVER (PARTITION BY cohort_definition_id) AS q3\n",
    "    FROM details\n",
    "  )\n",
    "  SELECT cohort_definition_id,\n",
    "         AVG(q3) - AVG(q1) AS IQR,\n",
    "         MIN(value) AS minimum,\n",
    "         AVG(q1) AS q1,\n",
    "         AVG(median) AS median,\n",
    "         AVG(q3) AS q3,\n",
    "         MAX(value) AS maximum,\n",
    "         'Time to Treatment' AS analysis_name\n",
    "  FROM quartiles\n",
    "  GROUP BY cohort_definition_id;\") %>%\n",
    "  SqlRender::render(\n",
    "    cdm_database_schema = cdmDatabaseSchema,\n",
    "    cohort_database_schema = cohortDatabaseSchema,\n",
    "    cohort_table = cohortTable,\n",
    "    target_ids = paste(targetIds, collapse = \",\")) %>% \n",
    "  assertNoParameters() %>% \n",
    "  SqlRender::translate(dbms(connection))\n",
    "\n",
    "df <- DatabaseConnector::querySql(connection, sql, snakeCaseToCamelCase = T)\n",
    "metrics <- rbind(metrics, df)\n",
    "andrData$metrics_distribution <- metrics\n",
    "\n",
    "disconnect(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188c5401",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# drop treatment complementary tables\n",
    "connection <- connect(connectionDetails)\n",
    "sql <- c(\"\n",
    "  DROP TABLE IF EXISTS @cohort_database_schema.drug_codesets;\n",
    "  DROP TABLE IF EXISTS @cohort_database_schema.treatment_tagged;\n",
    "  DROP TABLE IF EXISTS @cohort_database_schema.treatment_pat;\n",
    "  DROP TABLE IF EXISTS @cohort_database_schema.metastasis_date;\") %>% \n",
    "  SqlRender::render(cohort_database_schema = cohortDatabaseSchema) %>% \n",
    "  SqlRender::translate(dbms(connection))\n",
    "\n",
    "DatabaseConnector::executeSql(connection, sql)\n",
    "\n",
    "disconnect(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed274e0",
   "metadata": {},
   "source": [
    "# Counting cohorts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e42872e",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ParallelLogger::logInfo(\"Counting cohorts\")\n",
    "\n",
    "counts <- CohortGenerator::getCohortCounts(\n",
    "  connectionDetails = connectionDetails,\n",
    "  cohortDatabaseSchema = cohortDatabaseSchema,\n",
    "  cohortTable = cohortTable)\n",
    "\n",
    "if (nrow(counts) > 0) {\n",
    "  counts$databaseId <- databaseId\n",
    "  counts <- enforceMinCellValue(counts, \"cohortEntries\", minCellCount)\n",
    "  counts <- enforceMinCellValue(counts, \"cohortSubjects\", minCellCount)\n",
    "}\n",
    "\n",
    "readr::write_csv(counts, file.path(exportFolder, \"cohort_count.csv\"))\n",
    "andrData$cohort_count <- counts\n",
    "\n",
    "# Read in the cohort counts\n",
    "# counts <- readr::read_csv(file.path(exportFolder, \"cohort_count.csv\"))\n",
    "# colnames(counts) <- SqlRender::snakeCaseToCamelCase(colnames(counts))\n",
    "\n",
    "# Export the cohorts from the study\n",
    "# cohortsForExport <- loadCohortsForExportFromPackage(cohortIds = counts$cohortId)\n",
    "# andrData$cohort <- cohortsForExport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0241b612",
   "metadata": {},
   "source": [
    "# Extract feature counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c60961",
   "metadata": {
    "eval": false,
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "ParallelLogger::logInfo(\"Extract feature counts\")\n",
    "\n",
    "connection <- connect(connectionDetails)\n",
    "\n",
    "sql <- c(\"\n",
    "  SELECT \n",
    "    c.cohort_definition_id, \n",
    "    f.feature_cohort_definition_id,\n",
    "    f.window_id,\n",
    "    c.total_count,\n",
    "    f.feature_count,\n",
    "    1.0*f.feature_count/c.total_count AS mean,\n",
    "    sqrt(1.0*(total_count*f.feature_count - f.feature_count*f.feature_count)/(c.total_count*(c.total_count - 1))) AS sd\n",
    "  FROM (\n",
    "    SELECT cohort_definition_id, COUNT_BIG(DISTINCT subject_id) total_count\n",
    "    FROM @cohort_database_schema.@cohort_table \n",
    "    GROUP BY cohort_definition_id\n",
    "  ) c\n",
    "  INNER JOIN @cohort_database_schema.@feature_summary_table f -- Feature Count\n",
    "    ON c.cohort_definition_id = f.cohort_definition_id\n",
    "    AND c.total_count > 1 -- Prevent divide by zero;\n",
    "  \") %>% \n",
    "  SqlRender::render(\n",
    "    cohort_database_schema = cohortDatabaseSchema,\n",
    "    cohort_table = cohortTable,\n",
    "    feature_summary_table = featureSummaryTable) %>% \n",
    "  SqlRender::translate(dbms(connection))\n",
    "  \n",
    "data <- DatabaseConnector::querySql(connection, sql) \n",
    "names(data) <- SqlRender::snakeCaseToCamelCase(names(data))\n",
    "  \n",
    "# formatFeatureProportions ----\n",
    "featureTimeWindows <- readr::read_csv(here::here(\"inst\", \"settings\", \"featureTimeWindows.csv\"), \n",
    "                                      show_col_types = FALSE)\n",
    "\n",
    "featureCohorts <- readr::read_csv(here::here(\"inst\", \"settings\",\"CohortsToCreate.csv\"), show_col_types = FALSE) %>% \n",
    "  dplyr::filter(group %in% c(\"Stratification\", \"Outcome\")) %>% \n",
    "  dplyr::select(name, cohortId)\n",
    "\n",
    "data <- merge(data, featureTimeWindows, by = \"windowId\")\n",
    "data <- merge(data, featureCohorts, by.x = \"featureCohortDefinitionId\", by.y = \"cohortId\")\n",
    "names(data)[names(data) == 'name'] <- 'featureName'\n",
    "names(data)[names(data) == 'cohortDefinitionId'] <- 'cohortId'\n",
    "\n",
    "data$covariateId <- data$featureCohortDefinitionId * 1000 + data$windowId\n",
    "\n",
    "if (nrow(data) != 0) {\n",
    "  data$covariateName <- paste0(\"Cohort during day \", \n",
    "                               data$windowStart, \" through \", \n",
    "                               data$windowEnd, \" days \", \n",
    "                               data$windowType, \" the index: \", \n",
    "                               data$featureName)\n",
    "  \n",
    "  data$analysisId <- 10000\n",
    "  \n",
    "} else {\n",
    "  # Add empty columns\n",
    "  data <- data.frame(data, matrix(nrow = 0, ncol = 2))\n",
    "  data <- tibble::tibble(data) %>%\n",
    "    dplyr::rename(covariateName=X1, analysisId=X2) %>% \n",
    "    as.data.frame()\n",
    "}\n",
    "\n",
    "# format output\n",
    "if (nrow(featureProportions) > 0) {\n",
    "  featureProportions$databaseId <- databaseId\n",
    "  featureProportions <- enforceMinCellValue(featureProportions, \"featureCount\", minCellCount)\n",
    "  featureProportions <- featureProportions[featureProportions$totalCount >= minimumSubjectCountForCharacterization, ]\n",
    "}\n",
    "\n",
    "features <- formatCovariates(featureProportions)\n",
    "\n",
    "  if (nrow(data) > 0) {\n",
    "    data <- data[round(data$mean, 4) != 0, ]\n",
    "    covariates <- unique(data.table::setDT(data[, c(\"covariateId\", \"covariateName\", \"analysisId\")]))\n",
    "    colnames(covariates)[[3]] <- \"covariateAnalysisId\"\n",
    "  } else {\n",
    "    covariates <- data.table::data.table(\"covariateId\" = integer(), \"covariateName\" = character(), \"covariateAnalysisId\" = integer())\n",
    "  }\n",
    "  return(covariates)\n",
    "\n",
    "andrData$covariate <- features\n",
    "\n",
    "if (nrow(features) > 0) {\n",
    "  features$databaseId <- databaseId\n",
    "  features <- merge(features, counts[, c(\"cohortid\", \"cohortentries\")])\n",
    "  features <- enforceMinCellValue(features, \"mean\", minCellCount/features$cohortEntries)\n",
    "  features$sd[features$mean < 0] <- NA\n",
    "  features$cohortEntries <- NULL\n",
    "  features$mean <- round(features$mean, 3)\n",
    "  features$sd <- round(features$sd, 3)\n",
    "}\n",
    "  \n",
    "featureValues <- featureValues[,c(\"cohortId\", \"covariateId\", \"mean\", \"sd\", \"databaseId\")]\n",
    "andrData$covariate_value <- featureValues\n",
    "# Also keeping a raw output for debugging\n",
    "# writeToCsv(featureProportions, file.path(exportFolder, \"feature_proportions.csv\"))\n",
    "\n",
    "DatabaseConnector::disconnect(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177a2d06",
   "metadata": {},
   "source": [
    "# Cohort characterization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6430a2",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Note to package maintainer: If any of the logic to this changes, you'll need to revist\n",
    "# the function createBulkCharacteristics\n",
    "runCohortCharacterization <- function(cohortId, cohortName, covariateSettings, windowId, curIndex, totalCount) {\n",
    "  ParallelLogger::logInfo(\"- (windowId=\", windowId, \", \", curIndex, \" of \", totalCount, \") Creating characterization for cohort: \", cohortName)\n",
    "  data <- getCohortCharacteristics(connection = connection,\n",
    "                                   cdmDatabaseSchema = cdmDatabaseSchema,\n",
    "                                   oracleTempSchema = oracleTempSchema,\n",
    "                                   cohortDatabaseSchema = cohortDatabaseSchema,\n",
    "                                   cohortTable = cohortTable,\n",
    "                                   cohortId = cohortId,\n",
    "                                   covariateSettings = covariateSettings)\n",
    "  if (nrow(data) > 0) {\n",
    "    data$cohortId <- cohortId\n",
    "  }\n",
    "  \n",
    "  data$covariateId <- data$covariateId * 10 + windowId\n",
    "  return(data)\n",
    "}\n",
    "\n",
    "# Subset the cohorts to the target/strata for running feature extraction\n",
    "# that are >= 140 per protocol to improve efficency\n",
    "featureExtractionCohorts <-  loadCohortsForExportWithChecksumFromPackage(counts[counts$cohortSubjects >= minimumSubjectCountForCharacterization, c(\"cohortId\")]$cohortId)\n",
    "# Bulk approach ----------------------\n",
    "if (useBulkCharacterization) {\n",
    "  ParallelLogger::logInfo(\"********************************************************************************************\")\n",
    "  ParallelLogger::logInfo(\"Bulk characterization of all cohorts for all time windows\")\n",
    "  ParallelLogger::logInfo(\"********************************************************************************************\")\n",
    "  createBulkCharacteristics(connection, \n",
    "                            oracleTempSchema, \n",
    "                            cohortIds = featureExtractionCohorts$cohortId, \n",
    "                            cdmDatabaseSchema, \n",
    "                            cohortDatabaseSchema, \n",
    "                            cohortTable)\n",
    "  writeBulkCharacteristics(connection, oracleTempSchema, counts, minCellCount, databaseId, exportFolder, andrData)\n",
    "} else {\n",
    "  # Sequential Approach --------------------------------\n",
    "  if (incremental) {\n",
    "    recordKeepingFile <- file.path(incrementalFolder, \"CreatedAnalyses.csv\")\n",
    "  }\n",
    "  featureTimeWindows <- readr::read_csv(here::here(\"inst\", \"settings\", \"featureTimeWindows.csv\"), \n",
    "                                          show_col_types = FALSE)\n",
    "  \n",
    "  for (i in 1:nrow(featureTimeWindows)) {\n",
    "    windowStart <- featureTimeWindows$windowStart[i]\n",
    "    windowEnd <- featureTimeWindows$windowEnd[i]\n",
    "    windowId <- featureTimeWindows$windowId[i]\n",
    "    ParallelLogger::logInfo(\"********************************************************************************************\")\n",
    "    ParallelLogger::logInfo(paste0(\"Characterize concept features for start: \", windowStart, \", end: \", windowEnd, \" (windowId=\", windowId, \")\"))\n",
    "    ParallelLogger::logInfo(\"********************************************************************************************\")\n",
    "    createDemographics <- (i == 1)\n",
    "    covariateSettings <- FeatureExtraction::createCovariateSettings(useDemographicsGender = createDemographics,\n",
    "                                                                    useDemographicsAgeGroup = createDemographics,\n",
    "                                                                    useConditionGroupEraShortTerm = TRUE,\n",
    "                                                                    useDrugGroupEraShortTerm = TRUE,\n",
    "                                                                    shortTermStartDays = windowStart,\n",
    "                                                                    endDays = windowEnd)\n",
    "    task <- paste0(\"runCohortCharacterizationWindowId\", windowId)\n",
    "    if (incremental) {\n",
    "      subset <- subsetToRequiredCohorts(cohorts = featureExtractionCohorts,\n",
    "                                        task = task,\n",
    "                                        incremental = incremental,\n",
    "                                        recordKeepingFile = recordKeepingFile)\n",
    "    } else {\n",
    "      subset <- featureExtractionCohorts\n",
    "    }\n",
    "    \n",
    "    if (nrow(subset) > 0) {\n",
    "      for (j in 1:nrow(subset)) {\n",
    "        data <- runCohortCharacterization(cohortId = subset$cohortId[j],\n",
    "                                          cohortName = subset$cohortName[j],\n",
    "                                          covariateSettings = covariateSettings,\n",
    "                                          windowId = windowId,\n",
    "                                          curIndex = j,\n",
    "                                          totalCount = nrow(subset))\n",
    "        covariates <- formatCovariates(data)\n",
    "        writeToCsv(covariates, file.path(exportFolder, \"covariate.csv\"), incremental = incremental, covariateId = covariates$covariateId)\n",
    "        data <- formatCovariateValues(data, counts, minCellCount, databaseId)\n",
    "        writeToCsv(data, file.path(exportFolder, \"covariate_value.csv\"), incremental = incremental, cohortId = data$cohortId, data$covariateId)\n",
    "        if (incremental) {\n",
    "          recordTasksDone(cohortId = subset$cohortId[j],\n",
    "                          task = task,\n",
    "                          checksum = subset$checksum[j],\n",
    "                          recordKeepingFile = recordKeepingFile,\n",
    "                          incremental = incremental)\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546e0c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format results -----------------------------------------------------------------------------------\n",
    "ParallelLogger::logInfo(\"********************************************************************************************\")\n",
    "ParallelLogger::logInfo(\"Formatting Results\")\n",
    "ParallelLogger::logInfo(\"********************************************************************************************\")\n",
    "# Ensure that the covariate_value is free of any duplicate values. This can happen after more than\n",
    "# one run of the package.\n",
    "andrData$covariate_value <- andrData$covariate_value %>% dplyr::distinct()\n",
    "\n",
    "\n",
    "# # Export to zip file -------------------------------------------------------------------------------\n",
    "# exportResults(exportFolder, databaseId, cohortIdsToExcludeFromResultsExport)\n",
    "# delta <- Sys.time() - start\n",
    "# ParallelLogger::logInfo(paste(\"Running study took\",\n",
    "#                               signif(delta, 3),\n",
    "#                               attr(delta, \"units\")))\n",
    "Andromeda::saveAndromeda(andrData, file.path(exportFolder, \"study_results.zip\"))\n",
    "\n",
    "ParallelLogger::unregisterLogger(\"DEFAULT\")\n"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "tags,name,eval,-all",
   "main_language": "R",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
